{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4adb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import torch\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Play the .wav file\n",
    "Audio(\"digits/6.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c422aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self, directory, t_input, max_len, terminal_pad):\n",
    "        \"\"\"\n",
    "        directory: Directory containing the .wav files.\n",
    "        t_input: Time input array for all files.\n",
    "        max_len: Maximum length of time steps needed for all files.\n",
    "        terminal_pad: Number of zeros to pad at the end of each audio file.\n",
    "        \"\"\"\n",
    "        self.directory = directory\n",
    "        self.files = sorted([f for f in os.listdir(directory) if f.endswith('.wav')], key=lambda x: int(x.split('.')[0]))\n",
    "        self.t_input = t_input[:max_len]  # Truncate t_input to the maximum required length\n",
    "        self.terminal_pad = terminal_pad  # Fixed number of zeros to pad\n",
    "        self.wav_data_list = [self._load_and_pad(os.path.join(directory, f)) for f in self.files]  # Load and pad files\n",
    "        self.file_indices = []\n",
    "        self.total_length = 0\n",
    "\n",
    "        # Calculate lengths of all files and their indices\n",
    "        for i, wav_data in enumerate(self.wav_data_list):\n",
    "            length = wav_data.size(1)  # Assuming data is [channels, time], we take the time dimension\n",
    "            self.file_indices.extend([(i, j) for j in range(length)])\n",
    "            self.total_length += length\n",
    "\n",
    "    def _load_and_pad(self, file_path):\n",
    "        \"\"\"\n",
    "        Helper function to load, normalize, and pad the audio file.\n",
    "        \"\"\"\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "        data = torch.tensor(data).unsqueeze(0)  # Convert to tensor and add channel dimension\n",
    "\n",
    "        # Normalize the data to the range [-1, 1] based on int16\n",
    "        if data.dtype == torch.int16:\n",
    "            data = data / 32768.0  # Normalize int16 data\n",
    "        elif data.dtype == torch.int32:\n",
    "            data = data / 2147483648.0  # Normalize int32 data\n",
    "        elif data.dtype == torch.float32:\n",
    "            pass  # If it's already float, assume it's in [-1, 1]\n",
    "\n",
    "        # Pad the data with zeros at the end\n",
    "        pad_length = self.terminal_pad\n",
    "        data_padded = torch.nn.functional.pad(data, (0, pad_length), mode='constant', value=0)\n",
    "        #print(data_padded.shape, \"data padded\")\n",
    "        return data_padded\n",
    "\n",
    "    def _generate_target(self, wav_data):\n",
    "        \"\"\"\n",
    "        Helper function to generate the target tensor.\n",
    "        The target will have 1 in all positions except for the final terminal_pad zeros.\n",
    "        \"\"\"\n",
    "        target = torch.ones_like(wav_data)  # Create a target tensor with all ones\n",
    "        # Set the last terminal_pad positions to zero\n",
    "        target[:, -self.terminal_pad:] = 0\n",
    "        #print(target.shape, \"target shape\")\n",
    "        return target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx, local_idx = self.file_indices[idx]\n",
    "        wav_data = self.wav_data_list[file_idx][:, local_idx]  # Slice based on channel and index\n",
    "        t_step = self.t_input[local_idx]\n",
    "        target = self._generate_target(self.wav_data_list[file_idx])[:, local_idx]  # Generate the target tensor\n",
    "        return wav_data, t_step, target, file_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c49c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomConsecutiveSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size, consecutive_size):\n",
    "        \"\"\"\n",
    "        data_source: Dataset that returns (wav_data, time_step, file_idx)\n",
    "        batch_size: Number of consecutive segments in each batch\n",
    "        consecutive_size: How many consecutive steps to take for each sampled segment\n",
    "        \"\"\"\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.consecutive_size = consecutive_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(len(self.data_source) - self.consecutive_size + 1)\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            batch_indices = []\n",
    "            for j in range(i, min(i + self.batch_size, len(indices))):\n",
    "                start_idx = indices[j]\n",
    "                batch_indices.extend(range(start_idx, start_idx + self.consecutive_size))\n",
    "            yield batch_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source) - self.consecutive_size ) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549b1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveDifferenceHigherOrderLossBatch(nn.Module):\n",
    "    def __init__(self, consecutive_size,order=1):\n",
    "        super(ConsecutiveDifferenceHigherOrderLossBatch, self).__init__()\n",
    "        self.consecutive_size = consecutive_size\n",
    "        self.order = order\n",
    "    def forward(self, prediction, target):\n",
    "        pred_reshape = prediction.view(-1, self.consecutive_size)\n",
    "        target_reshape = target.view(-1, self.consecutive_size)\n",
    "        result = torch.tensor([0.0])\n",
    "        \n",
    "        pred_a = pred_reshape[ 1:, :]\n",
    "        pred_b = pred_reshape[:-1,:]\n",
    "        target_a = target_reshape[ 1:, :]\n",
    "        target_b = target_reshape[:-1,:]\n",
    "        for i in range(self.order):\n",
    "            \n",
    "            pred_dif = pred_a - pred_b\n",
    "            target_dif = target_a - target_b\n",
    "            pred_a = pred_dif[ 1:, :]\n",
    "            pred_b = pred_dif[:-1,:]\n",
    "            target_a = target_dif[ 1:, :]\n",
    "            target_b = target_dif[:-1,:]\n",
    "            \n",
    "            result +=  torch.mean((pred_dif - target_dif) ** 2)/self.order\n",
    "        return result\n",
    "    \n",
    "class ConsecutiveDifferenceHigherOrderLoss(nn.Module):\n",
    "    def __init__(self, consecutive_size,order=1):\n",
    "        super(ConsecutiveDifferenceHigherOrderLoss, self).__init__()\n",
    "        self.consecutive_size = consecutive_size\n",
    "        self.order = order\n",
    "    def forward(self, prediction, target):\n",
    "        pred_reshape = prediction.view(-1, self.consecutive_size)\n",
    "        target_reshape = target.view(-1, self.consecutive_size)\n",
    "        result = torch.tensor([0.0])\n",
    "        \n",
    "        pred_a = pred_reshape[:, 1:]\n",
    "        pred_b = pred_reshape[:, :-1]\n",
    "        target_a = target_reshape[:, 1:]\n",
    "        target_b = target_reshape[:, :-1]\n",
    "        for i in range(self.order):\n",
    "            \n",
    "            pred_dif = pred_a - pred_b\n",
    "            target_dif = target_a - target_b\n",
    "            pred_a = pred_dif[:, 1:]\n",
    "            pred_b = pred_dif[:, :-1]\n",
    "            target_a = target_dif[:, 1:]\n",
    "            target_b = target_dif[:, :-1]\n",
    "            \n",
    "            result +=  torch.mean((pred_dif - target_dif) ** 2)/self.order\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c34696",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"digits/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e38dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "def get_max_required_length(dir):\n",
    "    max_length = 0\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith('.wav'):  # Only process .wav files\n",
    "            file_path = os.path.join(dir, filename)\n",
    "            \n",
    "            # Read the .wav file\n",
    "            sample_rate, data = wavfile.read(file_path)\n",
    "            \n",
    "            # Get the length of the audio file (number of samples)\n",
    "            file_length = data.shape[0]  # shape[0] gives the number of samples (time dimension)\n",
    "            \n",
    "            # Update the max length if this file is longer\n",
    "            if file_length > max_length:\n",
    "                max_length = file_length\n",
    "\n",
    "    return max_length\n",
    "\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "def binary_sequence_tensor(num_bits, length):\n",
    "    # Create a tensor of shape (length,) with values from 0 to length - 1\n",
    "    t_values = torch.arange(1,length+1) #start with 1\n",
    "\n",
    "    # Create a tensor to store the binary representations\n",
    "    binary_tensor = ((t_values.unsqueeze(1) >> torch.arange(num_bits)) & 1).float()\n",
    "    binary_tensor[binary_tensor == 0] = -1\n",
    "    return binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94bc1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform data: tensor([[-0.1154],\n",
      "        [-0.1323],\n",
      "        [-0.1520],\n",
      "        [-0.1548],\n",
      "        [-0.1709],\n",
      "        [-0.2025],\n",
      "        [-0.2343],\n",
      "        [-0.1993],\n",
      "        [-0.1673],\n",
      "        [-0.1551],\n",
      "        [-0.0085],\n",
      "        [-0.0062],\n",
      "        [-0.0178],\n",
      "        [-0.0084],\n",
      "        [-0.0082],\n",
      "        [-0.0073],\n",
      "        [-0.0117],\n",
      "        [-0.0203],\n",
      "        [-0.0154],\n",
      "        [-0.0219],\n",
      "        [-0.0154],\n",
      "        [-0.0246],\n",
      "        [-0.0321],\n",
      "        [-0.0349],\n",
      "        [-0.0323],\n",
      "        [-0.0319],\n",
      "        [-0.0423],\n",
      "        [-0.0629],\n",
      "        [-0.0828],\n",
      "        [-0.1007],\n",
      "        [ 0.1937],\n",
      "        [ 0.1816],\n",
      "        [ 0.1628],\n",
      "        [ 0.1466],\n",
      "        [ 0.1357],\n",
      "        [ 0.1313],\n",
      "        [ 0.1233],\n",
      "        [ 0.1129],\n",
      "        [ 0.0952],\n",
      "        [ 0.0854],\n",
      "        [-0.0769],\n",
      "        [-0.0817],\n",
      "        [-0.0603],\n",
      "        [-0.0706],\n",
      "        [ 0.0197],\n",
      "        [ 0.0768],\n",
      "        [ 0.1479],\n",
      "        [ 0.2090],\n",
      "        [ 0.1808],\n",
      "        [ 0.1524],\n",
      "        [-0.0365],\n",
      "        [-0.0377],\n",
      "        [-0.0229],\n",
      "        [-0.0081],\n",
      "        [-0.0118],\n",
      "        [-0.0029],\n",
      "        [-0.0062],\n",
      "        [-0.0020],\n",
      "        [-0.0095],\n",
      "        [-0.0080],\n",
      "        [-0.0007],\n",
      "        [-0.0009],\n",
      "        [-0.0007],\n",
      "        [-0.0007],\n",
      "        [-0.0008],\n",
      "        [-0.0006],\n",
      "        [-0.0009],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.2278],\n",
      "        [-0.2045],\n",
      "        [-0.1761],\n",
      "        [-0.1787],\n",
      "        [-0.1880],\n",
      "        [-0.1286],\n",
      "        [-0.0529],\n",
      "        [ 0.0354],\n",
      "        [ 0.0787],\n",
      "        [ 0.0918],\n",
      "        [-0.3803],\n",
      "        [-0.3991],\n",
      "        [-0.4230],\n",
      "        [-0.4552],\n",
      "        [-0.4562],\n",
      "        [-0.4702],\n",
      "        [-0.4479],\n",
      "        [-0.4065],\n",
      "        [-0.3766],\n",
      "        [-0.3294],\n",
      "        [-0.2686],\n",
      "        [-0.1458],\n",
      "        [-0.0063],\n",
      "        [-0.0411],\n",
      "        [-0.1202],\n",
      "        [-0.3324],\n",
      "        [-0.4017],\n",
      "        [-0.2552],\n",
      "        [-0.0656],\n",
      "        [ 0.1247]])\n",
      "Time step: tensor([[ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        [-1.,  1.,  1.,  ..., -1., -1., -1.]])\n",
      "Target tensor: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "File index: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "target_pad = 20\n",
    "bits = 16\n",
    "\n",
    "max_len = get_max_required_length(directory)\n",
    "\n",
    "t_input = binary_sequence_tensor(bits, max_len+ target_pad)  # Example, adjust this to match your real t_input\n",
    "\n",
    "\n",
    "\n",
    "#this is for validating\n",
    "#t_input = np.linspace(1,max_len + target_pad,max_len + target_pad)\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = WaveformDataset(directory, t_input, max_len, target_pad)\n",
    "\n",
    "# Sampler setup as before\n",
    "batch_size = 10\n",
    "consecutive_size = 10\n",
    "sampler = RandomConsecutiveSampler(dataset, batch_size, consecutive_size)\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "# Example iteration through dataloader\n",
    "for batch in dataloader:\n",
    "    wav_data, t_step, target, file_idx = batch #right now this wraps arround, just fyi.  not sure its a bad thing.\n",
    "\n",
    "    if sum(target)%10 != 0:\n",
    "        print(\"Waveform data:\", wav_data)\n",
    "        print(\"Time step:\", t_step)\n",
    "        print(\"Target tensor:\", target)\n",
    "        print(\"File index:\", file_idx.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69497b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA model here\n",
    "from swissarmy import SeqModel\n",
    "\n",
    "config = {\n",
    "    't_seq_bits': 10,  # Example value for the input bit size\n",
    "    't_seq_len': 5,    # Example value for the sequence length\n",
    "    't_bits': 10,      # Example value for the bits used in the decoder\n",
    "\n",
    "    'encoder': {\n",
    "        't_layer_dim': 64,               # Example hidden layer dimension for encoder\n",
    "        't_num_layers': 2,                # Example number of layers in the encoder's initial layer\n",
    "        'fc_layers': 3,                   # Example number of fully connected layers in the encoder\n",
    "        'encoder_layers': 2,              # Example number of encoder layers\n",
    "        'one_hot_vocab_len': 10,          # Vocabulary size for one-hot encoding\n",
    "        'one_hot_embedding_dim': 32       # Embedding dimension for one-hot encoding\n",
    "    },\n",
    "\n",
    "    'decoder': {\n",
    "        't_layer_dim': 64,                # Example hidden layer dimension for decoder\n",
    "        't_num_layers': 2,                # Example number of layers in the decoder's initial layer\n",
    "        'fc_layers': 3,                   # Example number of fully connected layers in the decoder\n",
    "        'decoder_layers': 2                # Example number of decoder layers\n",
    "    },\n",
    "\n",
    "    'output': {\n",
    "        'mse_output_layers': 2,           # Number of layers in the MSE output head\n",
    "        'mse_dim': 64,                     # Hidden dimension for the MSE output head\n",
    "        'bce_output_layers': 2,            # Number of layers in the BCE output head\n",
    "        'bce_dim': 64                      # Hidden dimension for the BCE output head\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model = SeqModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724de4b8-3691-4446-9857-d168e9348158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (encoder): SeqEncoder(\n",
       "    (initial_layer): SwissArmyLayer(\n",
       "      (t_layers): ModuleList(\n",
       "        (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (embedding): Embedding(11, 32, padding_idx=10)\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x Linear(in_features=96, out_features=96, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList(\n",
       "          (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (embedding): Embedding(11, 32, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList(\n",
       "          (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (embedding): Embedding(11, 32, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SeqDecoder(\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList(\n",
       "          (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=352, out_features=352, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList(\n",
       "          (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=416, out_features=416, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mse_head): Sequential(\n",
       "    (0): Linear(in_features=416, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (bce_head): Sequential(\n",
       "    (0): Linear(in_features=416, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cad31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example usage:\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    \"num_digits\": 10,        # Number of possible digits\n",
    "    \"embedding_dim\": 64,      # Size of the embedding space\n",
    "    \"bits\": 16,               # Number of bits in the input tensor\n",
    "    \"hidden_dim\": 512,        # Number of units in the hidden layers\n",
    "    \"num_layers\": 5,         # Number of hidden layers\n",
    "    \"batch_size\": 100,        # Batch size\n",
    "    \"consecutive_size\": 20,   \n",
    "    \"terminal_pad\": 50      # Amount of padding for each audio file\n",
    "}\n",
    "\n",
    "# Instantiate the model\n",
    "model = DigitEmbeddingModel(\n",
    "    num_digits=hyperparams['num_digits'], \n",
    "    embedding_dim=hyperparams['embedding_dim'], \n",
    "    bits=hyperparams['bits'], \n",
    "    hidden_dim=hyperparams['hidden_dim'], \n",
    "    num_layers=hyperparams['num_layers']\n",
    ")\n",
    "\n",
    "##add more layers onto the embedding before t? res blocks? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams['consecutive_size'] = 50\n",
    "#hyperparams['batch_size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ffaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss functions\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "cdifb_loss = ConsecutiveDifferenceHigherOrderLossBatch(hyperparams['consecutive_size'],order=3)\n",
    "cdif_loss = ConsecutiveDifferenceHigherOrderLoss(hyperparams['consecutive_size'],order=3)\n",
    "\n",
    "# Dataset and DataLoader setup (using the dataset and sampler we worked on)\n",
    "directory = \"digits/\" # Replace with your actual directory path\n",
    "\n",
    "terminal_pad = hyperparams['terminal_pad']\n",
    "max_len = get_max_required_length(directory) + terminal_pad\n",
    "t_input = binary_sequence_tensor( hyperparams['bits'], max_len)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the dataset and sampler\n",
    "dataset = WaveformDataset(directory, t_input, max_len + terminal_pad, terminal_pad)\n",
    "sampler = RandomConsecutiveSampler(dataset, hyperparams['batch_size'], consecutive_size=hyperparams['consecutive_size'])\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        wav_data, t_step, target, file_idx = batch\n",
    "        \n",
    "        bce_output, mse_output = model(file_idx, t_step)\n",
    "        \n",
    "        # Compute losses\n",
    "        mse_loss = mse_loss_fn(mse_output*target, wav_data)  # Assuming the target is for MSE\n",
    "        bce_loss = bce_loss_fn(bce_output, target)  # Assuming the target is for BCE\n",
    "        cdif = cdif_loss(mse_output*target, wav_data)\n",
    "        #bc = bc_loss(outputs, targets)\n",
    "        cdif_b = cdifb_loss(mse_output*target, wav_data)\n",
    "        \n",
    "        \n",
    "        # Combine losses (you can weight them if needed)\n",
    "        total_loss = mse_loss + 0.1*bce_loss + 1.6*cdif + 0.4*cdif_b\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print progress for each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} MSE: {mse_loss.item():.6f} BCE: {bce_loss.item():.6f} CDIF: {cdif.item():.6f} CDIF_B: {cdif_b.item():.6f} Total Loss: {total_loss.item():.8f}\")\n",
    "\n",
    "print(\"all done sweetheart <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "file_path = 'digits/2.wav'\n",
    "sample_rate, file_data = wavfile.read(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34caf519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 418\n",
      "Processed batch 419\n",
      "Processed batch 420\n",
      "Processed batch 421\n",
      "Processed batch 422\n",
      "Processed batch 423\n",
      "Processed batch 424\n",
      "Processed batch 425\n",
      "Processed batch 426\n",
      "Processed batch 427\n",
      "Processed batch 428\n",
      "Processed batch 429\n",
      "Processed batch 430\n",
      "Processed batch 431\n",
      "Processed batch 432\n",
      "Processed batch 433\n",
      "Processed batch 434\n",
      "Processed batch 435\n",
      "Processed batch 436\n",
      "Processed batch 437\n",
      "Processed batch 438\n",
      "Processed batch 439\n",
      "Processed batch 440\n",
      "Processed batch 441\n",
      "Processed batch 442\n",
      "Processed batch 443\n",
      "Processed batch 444\n",
      "Processed batch 445\n",
      "Processed batch 446\n",
      "Processed batch 447\n",
      "Processed batch 448\n",
      "Processed batch 449\n",
      "Processed batch 450\n",
      "Processed batch 451\n",
      "Processed batch 452\n",
      "Processed batch 453\n",
      "Processed batch 454\n",
      "Processed batch 455\n",
      "Processed batch 456\n",
      "Processed batch 457\n",
      "Processed batch 458\n",
      "Processed batch 459\n",
      "Processed batch 460\n",
      "Processed batch 461\n",
      "Processed batch 462\n",
      "Processed batch 463\n",
      "Processed batch 464\n",
      "Processed batch 465\n",
      "Processed batch 466\n",
      "Processed batch 467\n",
      "Processed batch 468\n",
      "Processed batch 469\n",
      "Processed batch 470\n",
      "Processed batch 471\n",
      "Processed batch 472\n",
      "Processed batch 473\n",
      "Processed batch 474\n",
      "Processed batch 475\n",
      "Processed batch 476\n",
      "Processed batch 477\n",
      "Processed batch 478\n",
      "Processed batch 479\n",
      "Processed batch 480\n",
      "Processed batch 481\n",
      "Processed batch 482\n",
      "Processed batch 483\n",
      "Processed batch 484\n",
      "Processed batch 485\n",
      "Processed batch 486\n",
      "Processed batch 487\n",
      "Processed batch 488\n",
      "Processed batch 489\n",
      "Processed batch 490\n",
      "Processed batch 491\n",
      "Processed batch 492\n",
      "Processed batch 493\n",
      "Processed batch 494\n",
      "Processed batch 495\n",
      "Processed batch 496\n",
      "Processed batch 497\n",
      "Processed batch 498\n",
      "Processed batch 499\n",
      "Processed batch 500\n",
      "Processed batch 501\n",
      "Processed batch 502\n",
      "Processed batch 503\n",
      "Processed batch 504\n",
      "Processed batch 505\n",
      "Processed batch 506\n",
      "Processed batch 507\n",
      "Processed batch 508\n",
      "Processed batch 509\n",
      "Processed batch 510\n",
      "Processed batch 511\n",
      "Processed batch 512\n",
      "Processed batch 513\n",
      "Processed batch 514\n",
      "Processed batch 515\n",
      "Processed batch 516\n",
      "Processed batch 517\n",
      "Processed batch 518\n",
      "Processed batch 519\n",
      "Processed batch 520\n",
      "Processed batch 521\n",
      "Processed batch 522\n",
      "Processed batch 523\n",
      "Processed batch 524\n",
      "Processed batch 525\n",
      "Processed batch 526\n",
      "Processed batch 527\n",
      "Processed batch 528\n",
      "Processed batch 529\n",
      "Processed batch 530\n",
      "Processed batch 531\n",
      "Processed batch 532\n",
      "Processed batch 533\n",
      "Processed batch 534\n",
      "Processed batch 535\n",
      "Processed batch 536\n",
      "Processed batch 537\n",
      "Processed batch 538\n",
      "Processed batch 539\n",
      "Processed batch 540\n",
      "Processed batch 541\n",
      "Processed batch 542\n",
      "Processed batch 543\n",
      "Processed batch 544\n",
      "Processed batch 545\n",
      "Processed batch 546\n",
      "Processed batch 547\n",
      "Processed batch 548\n",
      "Processed batch 549\n",
      "Processed batch 550\n",
      "Processed batch 551\n",
      "Processed batch 552\n",
      "Processed batch 553\n",
      "Processed batch 554\n",
      "Processed batch 555\n",
      "Processed batch 556\n",
      "Processed batch 557\n",
      "Processed batch 558\n",
      "Processed batch 559\n",
      "Processed batch 560\n",
      "Processed batch 561\n",
      "Processed batch 562\n",
      "Processed batch 563\n",
      "Processed batch 564\n",
      "Processed batch 565\n",
      "Processed batch 566\n",
      "Processed batch 567\n",
      "Processed batch 568\n",
      "Processed batch 569\n",
      "Processed batch 570\n",
      "Processed batch 571\n",
      "Processed batch 572\n",
      "Processed batch 573\n",
      "Processed batch 574\n",
      "Processed batch 575\n",
      "Processed batch 576\n",
      "Processed batch 577\n",
      "Processed batch 578\n",
      "Processed batch 579\n",
      "Processed batch 580\n",
      "Processed batch 581\n",
      "Processed batch 582\n",
      "Processed batch 583\n",
      "Processed batch 584\n",
      "Processed batch 585\n",
      "Processed batch 586\n",
      "Processed batch 587\n",
      "Processed batch 588\n",
      "Processed batch 589\n",
      "Processed batch 590\n",
      "Processed batch 591\n",
      "Processed batch 592\n",
      "Processed batch 593\n",
      "Processed batch 594\n",
      "Processed batch 595\n",
      "Processed batch 596\n",
      "Processed batch 597\n",
      "Processed batch 598\n",
      "Processed batch 599\n",
      "Processed batch 600\n",
      "Processed batch 601\n",
      "Processed batch 602\n",
      "Processed batch 603\n",
      "Processed batch 604\n",
      "Processed batch 605\n",
      "Processed batch 606\n",
      "Processed batch 607\n",
      "Processed batch 608\n",
      "Processed batch 609\n",
      "Processed batch 610\n",
      "Processed batch 611\n",
      "Processed batch 612\n",
      "Processed batch 613\n",
      "Processed batch 614\n",
      "Processed batch 615\n",
      "Processed batch 616\n",
      "Processed batch 617\n",
      "Processed batch 618\n",
      "Processed batch 619\n",
      "Processed batch 620\n",
      "Processed batch 621\n",
      "Processed batch 622\n",
      "Processed batch 623\n",
      "Processed batch 624\n",
      "Processed batch 625\n",
      "Processed batch 626\n",
      "Processed batch 627\n",
      "Processed batch 628\n",
      "Processed batch 629\n",
      "Processed batch 630\n",
      "Processed batch 631\n",
      "Processed batch 632\n",
      "Processed batch 633\n",
      "Processed batch 634\n",
      "Processed batch 635\n",
      "Processed batch 636\n",
      "Processed batch 637\n",
      "Processed batch 638\n",
      "Processed batch 639\n",
      "Processed batch 640\n",
      "Processed batch 641\n",
      "Processed batch 642\n",
      "Processed batch 643\n",
      "Processed batch 644\n",
      "Processed batch 645\n",
      "Processed batch 646\n",
      "Processed batch 647\n",
      "Processed batch 648\n",
      "Processed batch 649\n",
      "Processed batch 650\n",
      "Processed batch 651\n",
      "Processed batch 652\n",
      "Processed batch 653\n",
      "Processed batch 654\n",
      "Processed batch 655\n",
      "Processed batch 656\n",
      "Processed batch 657\n",
      "Processed batch 658\n",
      "Processed batch 659\n",
      "Processed batch 660\n",
      "Processed batch 661\n",
      "Processed batch 662\n",
      "Processed batch 663\n",
      "Processed batch 664\n",
      "Processed batch 665\n",
      "Processed batch 666\n",
      "Processed batch 667\n",
      "Processed batch 668\n",
      "Processed batch 669\n",
      "Processed batch 670\n",
      "Processed batch 671\n",
      "Processed batch 672\n",
      "Processed batch 673\n",
      "Processed batch 674\n",
      "Processed batch 675\n",
      "Processed batch 676\n",
      "Processed batch 677\n",
      "Processed batch 678\n",
      "Processed batch 679\n",
      "Processed batch 680\n",
      "Processed batch 681\n",
      "Processed batch 682\n",
      "Processed batch 683\n",
      "Processed batch 684\n",
      "Processed batch 685\n",
      "Processed batch 686\n",
      "Processed batch 687\n",
      "Processed batch 688\n",
      "Processed batch 689\n",
      "Processed batch 690\n",
      "Processed batch 691\n",
      "Processed batch 692\n",
      "Processed batch 693\n",
      "Processed batch 694\n",
      "Processed batch 695\n",
      "Processed batch 696\n",
      "Processed batch 697\n",
      "Processed batch 698\n",
      "Processed batch 699\n",
      "Processed batch 700\n",
      "Processed batch 701\n",
      "Processed batch 702\n",
      "Processed batch 703\n",
      "Processed batch 704\n",
      "Processed batch 705\n",
      "Processed batch 706\n",
      "Processed batch 707\n",
      "Processed batch 708\n",
      "Processed batch 709\n",
      "Processed batch 710\n",
      "Processed batch 711\n",
      "Processed batch 712\n",
      "Processed batch 713\n",
      "Processed batch 714\n",
      "Processed batch 715\n",
      "Processed batch 716\n",
      "Processed batch 717\n",
      "Processed batch 718\n",
      "Processed batch 719\n",
      "Processed batch 720\n",
      "Processed batch 721\n",
      "Processed batch 722\n",
      "Processed batch 723\n",
      "Processed batch 724\n",
      "Processed batch 725\n",
      "Processed batch 726\n",
      "Processed batch 727\n",
      "Processed batch 728\n",
      "Processed batch 729\n",
      "Processed batch 730\n",
      "Processed batch 731\n",
      "Processed batch 732\n",
      "Processed batch 733\n",
      "Processed batch 734\n",
      "Processed batch 735\n",
      "Processed batch 736\n",
      "Processed batch 737\n",
      "Processed batch 738\n",
      "Processed batch 739\n",
      "Processed batch 740\n",
      "Processed batch 741\n",
      "Processed batch 742\n",
      "Processed batch 743\n",
      "Processed batch 744\n",
      "Processed batch 745\n",
      "Processed batch 746\n",
      "Processed batch 747\n",
      "Processed batch 748\n",
      "Processed batch 749\n",
      "Processed batch 750\n",
      "Processed batch 751\n",
      "Final BCE output shape: torch.Size([15020, 1])\n",
      "Final MSE output shape: torch.Size([15020, 1])\n"
     ]
    }
   ],
   "source": [
    "file_num = 6\n",
    "file_idx = (torch.ones((t_input.shape[0])) * file_num).to(int)\n",
    "\n",
    "t_step = t_input\n",
    "\n",
    "all_bce_outputs = []\n",
    "all_mse_outputs = []\n",
    "\n",
    "batch_size = 20\n",
    "# Loop through batches without shuffling\n",
    "for i in range(0, len(file_idx), batch_size):\n",
    "    batch_file_idx = file_idx[i:i+batch_size]\n",
    "    batch_t_step = t_step[i:i+batch_size]\n",
    "    \n",
    "    # Pass the batch through the model\n",
    "    with torch.no_grad():\n",
    "        bce_output, mse_output = model(batch_file_idx, batch_t_step)\n",
    "        \n",
    "    # Append outputs to the lists\n",
    "    all_bce_outputs.append(bce_output)\n",
    "    all_mse_outputs.append(mse_output)\n",
    "    \n",
    "    print(f\"Processed batch {i // batch_size + 1}\")\n",
    "\n",
    "# Concatenate all batches into final tensors\n",
    "final_bce_output = torch.cat(all_bce_outputs, dim=0)\n",
    "final_mse_output = torch.cat(all_mse_outputs, dim=0)\n",
    "\n",
    "# Now you have the complete outputs for all batches\n",
    "print(\"Final BCE output shape:\", final_bce_output.shape)\n",
    "print(\"Final MSE output shape:\", final_mse_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fe765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming final_bce_output and final_mse_output are already computed\n",
    "# and have been concatenated from batches\n",
    "\n",
    "# Example plotting code for final_bce_output and final_mse_output\n",
    "\n",
    "# Plot BCE Output\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(final_bce_output.numpy(), label=\"BCE Output\")\n",
    "plt.title(\"BCE Output over Time Steps\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"BCE Output\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot MSE Output\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.plot(final_mse_output.numpy(), label=\"MSE Output\")\n",
    "\n",
    "plt.title(\"MSE Output over Time Steps\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"MSE Output\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming final_bce_output is a 1D tensor with the accumulated BCE outputs\n",
    "\n",
    "# Find the index of the first value below 0.5\n",
    "below_threshold_indices = (final_bce_output < 0.5).nonzero(as_tuple=True)[0]\n",
    "first_below_threshold_idx = 0\n",
    "if len(below_threshold_indices) > 0:\n",
    "    first_below_threshold_idx = below_threshold_indices[0].item()  # Get the first index\n",
    "    print(f\"The first instance where BCE output is below 0.5 is at index {first_below_threshold_idx}\")\n",
    "else:\n",
    "    print(\"No value below 0.5 was found in the BCE output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_below_threshold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE Output\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(file_data/32768, label=\"Target Output\")\n",
    "plt.plot(final_mse_output.numpy()[:first_below_threshold_idx], label=\"MSE Output\")\n",
    "\n",
    "plt.title(\"MSE Output over Time Steps\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"MSE Output\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "##sibilant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17593b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "\n",
    "def tensor_to_wav(tensor, filename, sample_rate=44100,cut_off=-1 ):\n",
    "    # Convert tensor to numpy array and detach if needed\n",
    "    data = tensor.detach().cpu().numpy()[:cut_off]\n",
    "    # Normalize to the range [-1, 1]\n",
    "    #data = data / np.max(np.abs(data))\n",
    "\n",
    "    # Convert to 16-bit PCM format (values between -32768 and 32767)\n",
    "    data_int16 = np.int16(data * 32768)\n",
    "\n",
    "    # Write the .wav file\n",
    "    write(filename, sample_rate, data_int16)\n",
    "    print(f\"Saved as {filename}\")\n",
    "\n",
    "# Example usage with your model predictions (assuming predictions are in range -1 to 1):\n",
    "# predictions is the output tensor from the model\n",
    "tensor_to_wav(final_mse_output, \"test_2.wav\", sample_rate=sample_rate,cut_off = first_below_threshold_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e789e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Play the .wav file\n",
    "Audio(\"test_2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee84c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(model, \"first_try_digits.pth\") #this is the first one!!!!! it is intelligible, even tho it is grainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"first_try_digits_cdif.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e378dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"two_wide_digits_cdif.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"five_wide_digits_cdif.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"five_wide_digits_cdif.pth\")\n",
    "\n",
    "# Set the model to evaluation mode (if you're using it for inference)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "if you have a simple embedding for each digit, what if its more complicated? every digit was a little neural network.\n",
    "\n",
    "forget about that.  \n",
    "higher than 16, 256? fundamentally if you are \n",
    "limited by categories.  those are the words.  \n",
    "\n",
    "maybe start with some embeddings.  combined in some way? \n",
    "\n",
    "get this un noisy.  \n",
    "\n",
    "could you use this to classify digits.  \n",
    "\n",
    "text to speach kind of thing.  learn the phoneme.  \n",
    "\n",
    "multiple outputs that sum? look at what the before thing looks like.  \n",
    "\n",
    "split those earlier? \n",
    "\n",
    "why don't we use a sequential model.  \n",
    "\n",
    "mamba?\n",
    "\n",
    "mess with the t for the embedding? \n",
    "\n",
    "position encoding?!\n",
    "\n",
    "residual block? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
