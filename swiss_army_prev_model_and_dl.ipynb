{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bec28fd-ab6d-4215-a35a-2d681195f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_prev_preload import WaveformDatasetPreload\n",
    "from sampler_prev import RandomConsecutiveSampler\n",
    "from losses import ConsecutiveDifferenceHigherOrderLossBatch, ConsecutiveDifferenceHigherOrderLoss\n",
    "from swissarmy_prev import SeqModel\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efebe3c2-8ce3-46c1-ac76-05a8214a5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_tensor(num_bits, length):\n",
    "    # Create an array of integers from 0 to length - 1\n",
    "    t = np.arange(length)\n",
    "    # Generate the sine waves for each bit\n",
    "    sine_tensor = np.zeros((length, num_bits))  # Initialize the tensor\n",
    "    \n",
    "    for i in range(num_bits):\n",
    "        frequency = (np.pi / (2 ** i))  # Calculate frequency based on the number of bits\n",
    "        sine_tensor[:, i] = np.cos(frequency * (t))  # Fill the tensor with sine values\n",
    "\n",
    "    return sine_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d117af1-8ee4-4578-9eac-936e89d0d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits = 21\n",
    "max_len = 100_000\n",
    "seq_bits = 4\n",
    "seq_max_len = 2\n",
    "pred_prev = 3\n",
    "directory = \"digits_two/\"\n",
    "terminal_pad = 11\n",
    "seq_vocab_len = 10\n",
    "\n",
    "# Sampler setup as before\n",
    "batch_size = 200\n",
    "consecutive_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638eda3a-1bd4-4231-ba3d-49c7a4655907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 21])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "t_input = torch.tensor(generate_sine_tensor(num_bits,max_len)).float()\n",
    "print(t_input.shape)\n",
    "\n",
    "seq_t = torch.tensor(generate_sine_tensor(seq_bits,seq_max_len)).float()\n",
    "print(seq_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cb86a2-a43c-4365-a5f1-3684461a3b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00],\n",
       "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  ...,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00, -1.0000e+00,  6.1232e-17,  ...,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00],\n",
       "        ...,\n",
       "        [-1.0000e+00,  9.2903e-12, -7.0711e-01,  ...,  3.6386e-01,\n",
       "          8.2579e-01,  9.5546e-01],\n",
       "        [ 1.0000e+00, -1.0000e+00, -5.9268e-12,  ...,  3.6385e-01,\n",
       "          8.2579e-01,  9.5545e-01],\n",
       "        [-1.0000e+00, -1.4417e-11,  7.0711e-01,  ...,  3.6384e-01,\n",
       "          8.2578e-01,  9.5545e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d19853-d5b9-4caf-9e8e-a0167ba150b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1980676f-4a26-468c-bba3-7d14cb894683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaveformDatasetPreload(directory, t_input, max_len, terminal_pad, seq_vocab_len, seq_max_len, seq_t,pred_prev)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "sampler = RandomConsecutiveSampler(dataset, batch_size, consecutive_size)\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378851b8-8cff-4b44-93ae-0c4598979403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27424])\n",
      "torch.Size([1, 27424, 3])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.wav_data_list[0].shape)\n",
    "print(dataset.pred_data_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c2984f-1270-46ee-a372-ba228a569f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n",
      "Waveform data: torch.Size([2000, 1])\n",
      "Time step: torch.Size([2000, 21])\n",
      "Target tensor: torch.Size([2000, 1])\n",
      "File index: torch.Size([2000, 2])\n",
      "File index: torch.Size([2000, 2, 4])\n",
      "Previous Predictions: torch.Size([2000, 3])\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    wav_data, t_step, target, file_idx, seq_inputs, prev_target = batch #right now this wraps arround, just fyi.  not sure its a bad thing.\n",
    "\n",
    "    print(\"Waveform data:\", wav_data.shape)\n",
    "    print(\"Time step:\", t_step.shape)\n",
    "    print(\"Target tensor:\", target.shape)\n",
    "    print(\"File index:\", file_idx.shape)\n",
    "    print(\"File index:\", seq_inputs.shape)\n",
    "    print(\"Previous Predictions:\", prev_target.shape)\n",
    "    #print(wav_data)\n",
    "    #print(prev_target)\n",
    "    iteration = iteration + 1\n",
    "    if iteration > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f6679b-16f1-4c3f-b363-92b2dc5e141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    't_seq_bits': seq_bits,  # Example value for the input bit size\n",
    "    't_seq_len': seq_max_len,    # Example value for the sequence length\n",
    "    't_bits': num_bits,      # Example value for the bits used in the decoder\n",
    "\n",
    "    'encoder': {\n",
    "        't_layer_dim': 0,               # Example hidden layer dimension for encoder\n",
    "        't_num_layers': 0,                # Example number of layers in the encoder's initial layer\n",
    "        'fc_layers': 4,                   # Example number of fully connected layers in the encoder\n",
    "        'encoder_layers': 2,              # Example number of encoder layers\n",
    "        'one_hot_vocab_len': 10,          # Vocabulary size for one-hot encoding\n",
    "        'one_hot_embedding_dim': 20       # Embedding dimension for one-hot encoding\n",
    "    },\n",
    "\n",
    "    'decoder': {\n",
    "        't_layer_dim': 0,                # Example hidden layer dimension for decoder\n",
    "        't_num_layers': 0,                # Example number of layers in the decoder's initial layer\n",
    "        'fc_layers': 4,                   # Example number of fully connected layers in the decoder\n",
    "        'decoder_layers': 3,                # Example number of decoder layers\n",
    "        'pred_prev_dim': pred_prev\n",
    "    },\n",
    "\n",
    "    'output': {\n",
    "        'mse_output_layers': 2,           # Number of layers in the MSE output head\n",
    "        'mse_dim': 64,                     # Hidden dimension for the MSE output head\n",
    "        'bce_output_layers': 2,            # Number of layers in the BCE output head\n",
    "        'bce_dim': 64                      # Hidden dimension for the BCE output head\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861688d4-3ae0-425d-a636-299aa6a44a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a159c23-a767-47db-8b6d-4504d3d8c511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (encoder): SeqEncoder(\n",
       "    (initial_layer): SwissArmyLayer(\n",
       "      (t_layers): ModuleList()\n",
       "      (embedding): Embedding(11, 20, padding_idx=10)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=24, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=48, out_features=48, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=72, out_features=72, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SeqDecoder(\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=120, out_features=120, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=144, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mse_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (bce_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea636d9-a25c-4f9c-a0d0-43c09105cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1]) torch.Size([2000, 1])\n"
     ]
    }
   ],
   "source": [
    "bce_output, mse_output = model(seq_inputs,file_idx,t_step,prev_target)\n",
    "print(bce_output.shape, mse_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68acd0b6-4bed-4fc9-bd9e-adc904bd42f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 5623it [17:20,  5.40it/s]                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 MSE: 0.000368 BCE: 0.000000 CDIF: 0.001375  Total Loss: 0.00489123\n",
      "all done sweetheart <3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "prev_target_list = []\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "cdifb_loss = ConsecutiveDifferenceHigherOrderLossBatch(consecutive_size,order=3)\n",
    "cdif_loss = ConsecutiveDifferenceHigherOrderLoss(consecutive_size,order=3)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    #for batch in dataloader:\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        wav_data, t_step, target, file_idx, seq_inputs, prev_target = batch\n",
    "        \n",
    "        bce_output, mse_output = model(seq_inputs,file_idx,t_step,prev_target)\n",
    "        # Compute losses\n",
    "        mse_loss = mse_loss_fn(mse_output*target, wav_data)  # Assuming the target is for MSE # is this accomplishing what i want?\n",
    "        bce_loss = bce_loss_fn(bce_output, target)  # Assuming the target is for BCE\n",
    "        cdif = cdif_loss(mse_output*target, wav_data)\n",
    "        #bc = bc_loss(outputs, targets)\n",
    "        cdif_b = cdifb_loss(mse_output*target, wav_data)\n",
    "        \n",
    "        \n",
    "        # Combine losses (you can weight them if needed)\n",
    "        total_loss = mse_loss + 0.2*bce_loss + 1.9*cdif  + 0.5*cdif_b\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print progress for each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} MSE: {mse_loss.item():.6f} BCE: {bce_loss.item():.6f} CDIF: {cdif.item():.6f}  Total Loss: {total_loss.item():.8f}\")\n",
    "    torch.save(model, \"new_model.pth\")\n",
    "print(\"all done sweetheart <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbdc714d-bcb3-4d4b-99f6-958f27675680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (encoder): SeqEncoder(\n",
       "    (initial_layer): SwissArmyLayer(\n",
       "      (t_layers): ModuleList()\n",
       "      (embedding): Embedding(11, 20, padding_idx=10)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=24, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=48, out_features=48, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=72, out_features=72, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SeqDecoder(\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=120, out_features=120, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=144, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mse_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (bce_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##i need inference and then a noise term for the training prev_pred input.  \n",
    "model = torch.load(\"new_model.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de49ab9-2a62-4d16-b5b0-36b15a8514e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2]) torch.Size([1, 2, 4]) torch.Size([1, 21])\n"
     ]
    }
   ],
   "source": [
    "digits = \"1\"\n",
    "rep = t_input.shape[0] #this is good, \n",
    "input_seq_t = seq_t\n",
    "\n",
    "file = [int(char) for char in digits] \n",
    "input_seq_t[len(digits):] = 0\n",
    "input_seq_t = input_seq_t.unsqueeze(0)\n",
    "\n",
    "file = file + [10] * (2 - len(file))\n",
    "file = torch.tensor(file)\n",
    "file = file.unsqueeze(0)\n",
    "\n",
    "\n",
    "t_input_eval = t_input[0]\n",
    "t_input_eval = t_input_eval.unsqueeze(0)\n",
    "print(file.shape,input_seq_t.shape, t_input_eval.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f6aa3f-0d8b-40e9-907e-3e3acc0e6bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " tensor([[ 1, 10]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_t, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f3d6e2-b8e5-4e76-a671-423caa81640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "prev_target = torch.tensor([[0.0,0.0,0.0]])\n",
    "print(prev_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af6ae5d-a7b8-4440-8c8f-7bdffb7ea8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[-0.0092]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_seq_t,file,t_input_eval,prev_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b5e10-58fa-410f-bc9a-ef42b54322bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
