{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d31adfa",
   "metadata": {},
   "source": [
    "This is going to randomly sample, but then also return consective data points. both based on a dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b0e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self, wav_data, t_input):\n",
    "        self.wav_data = wav_data\n",
    "        self.time_steps = t_input\n",
    "        self.length = len(wav_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.wav_data[idx], self.time_steps[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4be1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomConsecutiveSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size, consecutive_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.consecutive_size = consecutive_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(len(self.data_source) - self.consecutive_size + 1)\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            batch_indices = []\n",
    "            for j in range(i, min(i + self.batch_size, len(indices))):\n",
    "                start_idx = indices[j]\n",
    "                batch_indices.extend(range(start_idx, start_idx + self.consecutive_size))\n",
    "            yield batch_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_source) - self.consecutive_size ) // self.batch_size\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "wav_data = np.linspace(1,100,100).tolist()  # Example waveform data\n",
    "t_input = np.linspace(1,100,100).tolist()  # Example time step data\n",
    "\n",
    "dataset = WaveformDataset(wav_data, t_input)\n",
    "batch_size = 17\n",
    "consecutive_size = 13\n",
    "\n",
    "sampler = RandomConsecutiveSampler(dataset, batch_size, consecutive_size)\n",
    "data_loader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8052467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_dif(prediction, target, consecutive_size):\n",
    "    \"\"\"\n",
    "    This will calculate the differences across consecutive points.  \n",
    "    use RandomConsecutiveSampler for intended results\n",
    "    \"\"\"\n",
    "    pred_reshape = prediction.view(-1,consecutive_size)\n",
    "    target_reshape = target.view(-1,consecutive_size)\n",
    "    pred_dif = pred_reshape[:,1:] - pred_reshape[:,:-1]\n",
    "    target_dif = target_reshape[:,1:] - target_reshape[:,:-1]\n",
    "    return torch.mean((pred_dif - target_dif)**2)\n",
    "    \n",
    "#variations.  you can do the differences with all the other consecutive points.  \n",
    "# you could do differences along the batch.  those are consecutive points but they shift one each time\n",
    "# weight those with the dif in t.  that could be interesting.  \n",
    "#might add in another dataloader? a completely random one? what if you use mse on the random one? \n",
    "#thats interesting.  or maybe just weird.  \n",
    "#no its interesting.  you learn the slopes from differences, then the vertical shift from mse on different points.  \n",
    "# try these on a single wave to learn frequency.  then add in phi?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e326d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1520, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data loader\n",
    "for batch in data_loader:\n",
    "    waveforms, time_steps = batch\n",
    "    \n",
    "    x = consecutive_dif(waveforms,waveforms+torch.rand_like(waveforms),consecutive_size)\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tomorrow, i want to make the layer that duplicates the input t, \n",
    "#and applies different A and phi, then sums them to make one output t. \n",
    "#so your first layers have lots and lots, and subsequent layers have few.  \n",
    "#that is going to be a tree.  i want to specify num branches and num layers.  \n",
    "\n",
    "#later we try it with triangle waves\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
