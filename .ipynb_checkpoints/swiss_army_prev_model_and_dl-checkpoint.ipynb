{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bec28fd-ab6d-4215-a35a-2d681195f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_prev_preload import WaveformDatasetPreload\n",
    "from sampler_prev import RandomConsecutiveSampler\n",
    "from losses import ConsecutiveDifferenceHigherOrderLossBatch, ConsecutiveDifferenceHigherOrderLoss\n",
    "from swissarmy_prev import SeqModel\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efebe3c2-8ce3-46c1-ac76-05a8214a5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_tensor(num_bits, length):\n",
    "    # Create an array of integers from 0 to length - 1\n",
    "    t = np.arange(length)\n",
    "    # Generate the sine waves for each bit\n",
    "    sine_tensor = np.zeros((length, num_bits))  # Initialize the tensor\n",
    "    \n",
    "    for i in range(num_bits):\n",
    "        frequency = (np.pi / (2 ** i))  # Calculate frequency based on the number of bits\n",
    "        sine_tensor[:, i] = np.cos(frequency * (t))  # Fill the tensor with sine values\n",
    "\n",
    "    return sine_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d117af1-8ee4-4578-9eac-936e89d0d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits = 21\n",
    "max_len = 100_000\n",
    "seq_bits = 4\n",
    "seq_max_len = 2\n",
    "pred_prev = 3\n",
    "directory = \"digits_two/\"\n",
    "terminal_pad = 11\n",
    "seq_vocab_len = 10\n",
    "\n",
    "# Sampler setup as before\n",
    "batch_size = 2\n",
    "consecutive_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638eda3a-1bd4-4231-ba3d-49c7a4655907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 21])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "t_input = torch.tensor(generate_sine_tensor(num_bits,max_len)).float()\n",
    "print(t_input.shape)\n",
    "\n",
    "seq_t = torch.tensor(generate_sine_tensor(seq_bits,seq_max_len)).float()\n",
    "print(seq_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d19853-d5b9-4caf-9e8e-a0167ba150b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1980676f-4a26-468c-bba3-7d14cb894683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaveformDatasetPreload(directory, t_input, max_len, terminal_pad, seq_vocab_len, seq_max_len, seq_t,pred_prev)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "sampler = RandomConsecutiveSampler(dataset, batch_size, consecutive_size)\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378851b8-8cff-4b44-93ae-0c4598979403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27424])\n",
      "torch.Size([27424, 3])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.wav_data_list[0].shape)\n",
    "print(dataset.pred_data_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b66a2-b1f1-4786-b555-164b028fbd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c2984f-1270-46ee-a372-ba228a569f42",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      4\u001b[0m     wav_data, t_step, target, file_idx, seq_inputs, prev_target \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;66;03m#right now this wraps arround, just fyi.  not sure its a bad thing.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaveform data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, wav_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Class Notes/Research/CSN/dataloader_prev_preload.py:120\u001b[0m, in \u001b[0;36mWaveformDatasetPreload.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    118\u001b[0m file_idx, local_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_indices[idx]\n\u001b[1;32m    119\u001b[0m wav_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav_data_list[file_idx][:, local_idx]  \u001b[38;5;66;03m# Slice based on channel and index\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m pred_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_data_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    121\u001b[0m t_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_input[local_idx]  \u001b[38;5;66;03m# Time input for the specific index\u001b[39;00m\n\u001b[1;32m    122\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_target(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav_data_list[file_idx])[:, local_idx]  \u001b[38;5;66;03m# Generate the target tensor\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    wav_data, t_step, target, file_idx, seq_inputs, prev_target = batch #right now this wraps arround, just fyi.  not sure its a bad thing.\n",
    "\n",
    "    print(\"Waveform data:\", wav_data.shape)\n",
    "    #print(\"Time step:\", t_step.shape)\n",
    "    #print(\"Target tensor:\", target.shape)\n",
    "    #print(\"File index:\", file_idx.shape)\n",
    "    #print(\"File index:\", seq_inputs.shape)\n",
    "    print(\"Previous Predictions:\", prev_target.shape)\n",
    "    #print(wav_data)\n",
    "    #print(prev_target)\n",
    "    iteration = iteration + 1\n",
    "    if iteration > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f6679b-16f1-4c3f-b363-92b2dc5e141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    't_seq_bits': seq_bits,  # Example value for the input bit size\n",
    "    't_seq_len': seq_max_len,    # Example value for the sequence length\n",
    "    't_bits': num_bits,      # Example value for the bits used in the decoder\n",
    "\n",
    "    'encoder': {\n",
    "        't_layer_dim': 0,               # Example hidden layer dimension for encoder\n",
    "        't_num_layers': 0,                # Example number of layers in the encoder's initial layer\n",
    "        'fc_layers': 4,                   # Example number of fully connected layers in the encoder\n",
    "        'encoder_layers': 2,              # Example number of encoder layers\n",
    "        'one_hot_vocab_len': 10,          # Vocabulary size for one-hot encoding\n",
    "        'one_hot_embedding_dim': 20       # Embedding dimension for one-hot encoding\n",
    "    },\n",
    "\n",
    "    'decoder': {\n",
    "        't_layer_dim': 0,                # Example hidden layer dimension for decoder\n",
    "        't_num_layers': 0,                # Example number of layers in the decoder's initial layer\n",
    "        'fc_layers': 4,                   # Example number of fully connected layers in the decoder\n",
    "        'decoder_layers': 3,                # Example number of decoder layers\n",
    "        'pred_prev_dim': pred_prev\n",
    "    },\n",
    "\n",
    "    'output': {\n",
    "        'mse_output_layers': 2,           # Number of layers in the MSE output head\n",
    "        'mse_dim': 64,                     # Hidden dimension for the MSE output head\n",
    "        'bce_output_layers': 2,            # Number of layers in the BCE output head\n",
    "        'bce_dim': 64                      # Hidden dimension for the BCE output head\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861688d4-3ae0-425d-a636-299aa6a44a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a159c23-a767-47db-8b6d-4504d3d8c511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (encoder): SeqEncoder(\n",
       "    (initial_layer): SwissArmyLayer(\n",
       "      (t_layers): ModuleList()\n",
       "      (embedding): Embedding(11, 20, padding_idx=10)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=24, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=48, out_features=48, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 20, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=72, out_features=72, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SeqDecoder(\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=120, out_features=120, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x Linear(in_features=144, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mse_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (bce_head): Sequential(\n",
       "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea636d9-a25c-4f9c-a0d0-43c09105cc3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bce_output, mse_output \u001b[38;5;241m=\u001b[39m model(\u001b[43mseq_inputs\u001b[49m,file_idx,t_step,prev_target)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bce_output\u001b[38;5;241m.\u001b[39mshape, mse_output\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "bce_output, mse_output = model(seq_inputs,file_idx,t_step,prev_target)\n",
    "print(bce_output.shape, mse_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68acd0b6-4bed-4fc9-bd9e-adc904bd42f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|                                     | 0/562212 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#for batch in dataloader:\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     wav_data, t_step, target, file_idx, seq_inputs, prev_target \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     17\u001b[0m     bce_output, mse_output \u001b[38;5;241m=\u001b[39m model(seq_inputs,file_idx,t_step,prev_target)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Class Notes/Research/CSN/dataloader_prev_preload.py:120\u001b[0m, in \u001b[0;36mWaveformDatasetPreload.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    118\u001b[0m file_idx, local_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_indices[idx]\n\u001b[1;32m    119\u001b[0m wav_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav_data_list[file_idx][:, local_idx]  \u001b[38;5;66;03m# Slice based on channel and index\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m pred_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_data_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    121\u001b[0m t_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_input[local_idx]  \u001b[38;5;66;03m# Time input for the specific index\u001b[39;00m\n\u001b[1;32m    122\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_target(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav_data_list[file_idx])[:, local_idx]  \u001b[38;5;66;03m# Generate the target tensor\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "prev_target_list = []\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "cdifb_loss = ConsecutiveDifferenceHigherOrderLossBatch(consecutive_size,order=3)\n",
    "cdif_loss = ConsecutiveDifferenceHigherOrderLoss(consecutive_size,order=3)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    #for batch in dataloader:\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        wav_data, t_step, target, file_idx, seq_inputs, prev_target = batch\n",
    "        print(prev_target.shape)\n",
    "        bce_output, mse_output = model(seq_inputs,file_idx,t_step,prev_target)\n",
    "        # Compute losses\n",
    "        mse_loss = mse_loss_fn(mse_output*target, wav_data)  # Assuming the target is for MSE # is this accomplishing what i want?\n",
    "        bce_loss = bce_loss_fn(bce_output, target)  # Assuming the target is for BCE\n",
    "        cdif = cdif_loss(mse_output*target, wav_data)\n",
    "        #bc = bc_loss(outputs, targets)\n",
    "        cdif_b = cdifb_loss(mse_output*target, wav_data)\n",
    "        \n",
    "        \n",
    "        # Combine losses (you can weight them if needed)\n",
    "        total_loss = mse_loss + 0.2*bce_loss + 1.9*cdif  + 0.5*cdif_b\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print progress for each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} MSE: {mse_loss.item():.6f} BCE: {bce_loss.item():.6f} CDIF: {cdif.item():.6f}  Total Loss: {total_loss.item():.8f}\")\n",
    "    torch.save(model, \"new_model.pth\")\n",
    "print(\"all done sweetheart <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041b804-51b4-450e-b7a0-8af9ca0ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_target_list[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc714d-bcb3-4d4b-99f6-958f27675680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
