{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac9d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "\n",
    "class TriangularWaveFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, t):\n",
    "        # Save context for backward computation\n",
    "        ctx.save_for_backward(t)\n",
    "        return 2 * torch.abs(2 * ( t - torch.floor((t + 0.5))) ) - 1\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        t, = ctx.saved_tensors\n",
    "        # Compute the gradient using the square_wave function\n",
    "        grad_input = grad_output * (-2 * (torch.floor(2*t ) % 2) + 1)\n",
    "        return grad_input\n",
    "\n",
    "def triangular_wave(t):\n",
    "    return TriangularWaveFunction.apply(t)\n",
    "\n",
    "torch.triangular_wave = triangular_wave\n",
    "\n",
    "\n",
    "##next i want to add phi with the triangle wave and see if that works. just do phi and amplitude?!\n",
    "#init? should the amplitudes be increasing or anything like that? what happens when your amplitude descreases? is that interesting?\n",
    "\n",
    "\n",
    "class SinWaveLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SinWaveLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        Sin wave with amplitude and phi params. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.phi = nn.Parameter(torch.randn(1)) \n",
    "        self.amplitude = nn.Parameter(torch.randn(1))\n",
    "        \n",
    "    def forward(self, t):\n",
    "        out = self.amplitude * torch.sin( t + self.phi)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TriangleWaveLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TriangleWaveLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        Triangle wave.  a and phi only.  and only 1 per layer\n",
    "        \"\"\"\n",
    "        self.phi = nn.Parameter(torch.randn(1))  # Parameter to be added\n",
    "        self.amplitude = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, t):\n",
    "        out = self.amplitude * torch.triangular_wave( t + self.phi)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class TriangleCombinationLayer(nn.Module):\n",
    "    def __init__(self, param_dim):\n",
    "        super(TriangleCombinationLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        Triangle wave.  a and phi only.  and only 1 per layer\n",
    "        \"\"\"\n",
    "        self.phi = nn.Parameter(torch.randn(param_dim))  # Parameter to be added\n",
    "        self.amplitude = nn.Parameter(torch.randn(param_dim))\n",
    "\n",
    "    def forward(self, t):\n",
    "        out = self.amplitude * torch.triangular_wave( t + self.phi)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SinOnlyChainNetwork(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(SinOnlyChainNetwork, self).__init__()\n",
    "        \"\"\"This is an early attempt, i don't remember it training\"\"\"\n",
    "        self.layers = nn.ModuleList([SinWaveLayer() for _ in range(L)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class TriangleChainNetwork(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(TriangleChainNetwork, self).__init__()\n",
    "        \"\"\"Triangle waves with a sin wave at the end.  L is just number of layers\"\"\"\n",
    "        self.layers = nn.ModuleList([TriangleWaveLayer() for _ in range(L-1)])\n",
    "        self.sin_layer = SinWaveLayer()\n",
    "    def forward(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.sin_layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SinAndLinearLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SinAndLinearLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        takes t as input.  t is batch x input_dim.  the coefficient transforms it into output dim shape\n",
    "        This was my first layer to learn frequency.  i added like 5 layers and it learned.  \n",
    "        This was the big break.  using \n",
    "        \"\"\"\n",
    "        \n",
    "        self.coeff = nn.Parameter(torch.randn(input_dim,output_dim))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the parameters to the input and then the sin function\n",
    "        #f = self.mul_param  #**2 + self.e\n",
    "        #print(x.shape)\n",
    "        out = torch.matmul(torch.sin(x),self.coeff)\n",
    "        return out\n",
    "\n",
    "class SinAndLinearNetwork(nn.Module):\n",
    "    def __init__(self,layer_dims):\n",
    "        super(SinAndLinearNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList([SinAndLinearLayer(i[0],i[1]) for i in layer_dims ])\n",
    "        \"\"\"\n",
    "        This is the one that trained!\n",
    "        WaveformDatasetConsecutive (tho random worked well too)\n",
    "        network_config = [[1,5],[5,10],[10,20],[20,50],[50,100],[100,50],[50,1]]\n",
    "        network = SinAndLinearNetwork(network_config)\n",
    "        network.train()\n",
    "        used the ProximalDiffLoss\n",
    "        used random consecutive dataloader.\n",
    "        \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "class testN(nn.Module):\n",
    "    def __init__(self,layer_dims):\n",
    "        super(testN, self).__init__()\n",
    "        self.layers = nn.ModuleList([SinAndLinearLayer3(i[0],i[1]) for i in layer_dims ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9869cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Losses\n",
    "\n",
    "class PhaseAgreementLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhaseAgreementLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        product = input * target\n",
    "        loss = torch.sum(1- torch.sigmoid(product +2))\n",
    "        return loss\n",
    "   \n",
    "class ProximalDiffLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProximalDiffLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        in_dif = input -input.T\n",
    "        t_dif = target - target.T\n",
    "        dif = in_dif - t_dif\n",
    "        square = dif **2\n",
    "        return torch.mean(square)\n",
    "    \n",
    "class SquareAreaLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareAreaLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, t, input, target):\n",
    "        \n",
    "        t_dif = t - t.T #no negative distances.\n",
    "        in_dif = input -input.T\n",
    "        t_dif = target - target.T\n",
    "        dif = in_dif - t_dif\n",
    "        areas = dif * t_dif\n",
    "        sqa = areas **2\n",
    "        return torch.mean(sqa)\n",
    "    \n",
    "    \n",
    "class ProximalCDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProximalCDLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        in_dif = input -input.T\n",
    "        t_dif = target - target.T\n",
    "        cd = 1 - F.cosine_similarity(in_dif, t_dif)\n",
    "        #square = cd **2\n",
    "        return torch.mean(cd)\n",
    "\n",
    "class BatchAreaDiffLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BatchAreaDiffLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, t, pred,target):\n",
    "        t = t - t.T\n",
    "        \n",
    "        pred = pred - pred.T\n",
    "        \n",
    "        target = target - target.T\n",
    "        loss = torch.abs(t * (target - pred))\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        return loss\n",
    "                         \n",
    "class BatchAreaCDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BatchAreaCDLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, t, pred,target):\n",
    "        t = t - t.T\n",
    "        \n",
    "        pred = pred - pred.T\n",
    "        \n",
    "        target = target - target.T\n",
    "        pred = t*pred\n",
    "        pred = pred.flatten()\n",
    "        target = t*target\n",
    "        target = target.flatten()\n",
    "        loss = 1 - F.cosine_similarity(pred, target, dim=0)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dataloaders:\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self, wav_data, t_input):\n",
    "        \"\"\"\n",
    "        dataset = WaveformDataset(data,data_t)\n",
    "        batch_size = hyperparameters['batch_size']\n",
    "        sampler = RandomBatchSampler(dataset, batch_size)\n",
    "        dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        self.wav_data = wav_data\n",
    "        self.time_steps = t_input\n",
    "        self.length = len(wav_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.wav_data[idx], self.time_steps[idx]\n",
    "\n",
    "class RandomBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = torch.randperm(len(self.data_source)).tolist()\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            yield indices[i:i + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source) // self.batch_size\n",
    "\n",
    "class WaveformDatasetConsecutive(Dataset):\n",
    "    def __init__(self, wav_data,t_input):\n",
    "        \"\"\"\n",
    "        This one worked with \n",
    "        dataset = WaveformDatasetConsecutive(data,data_t)\n",
    "        batch_size = hyperparameters['batch_size']\n",
    "        sampler = RandomBatchSamplerConsecutive(dataset, batch_size)\n",
    "        dataloader = DataLoader(dataset, batch_sampler=sampler)  \n",
    "        \n",
    "        \"\"\"\n",
    "        self.wav_data = wav_data\n",
    "        self.time_steps = t_input\n",
    "        self.length = len(wav_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.wav_data[idx], self.time_steps[idx]\n",
    "\n",
    "class RandomBatchSamplerConsecutive(Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = len(self.data_source) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of starting indices for each batch\n",
    "        starting_indices = list(range(0, len(self.data_source) - self.batch_size + 1, self.batch_size))\n",
    "        # Shuffle the starting indices\n",
    "        np.random.shuffle(starting_indices)\n",
    "        # Yield batches of consecutive indices\n",
    "        for start_idx in starting_indices:\n",
    "            yield list(range(start_idx, start_idx + self.batch_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42fed38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SinePaint(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SinePaint, self).__init__()\n",
    "        \n",
    "        # Initialize the weight matrix for input_dim + 1 to account for the intercept\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim + 1, output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Append a column of ones to the input for the intercept\n",
    "        batch_size = x.size(0)\n",
    "        ones = torch.ones(batch_size, 1, device=x.device)\n",
    "        x_with_intercept = torch.cat([x, ones], dim=1)\n",
    "        \n",
    "        # Perform the matrix multiplication with the weight parameter\n",
    "        x_transformed = torch.matmul(x_with_intercept, self.weight)\n",
    "        \n",
    "        # Pass the result through torch.sin\n",
    "        output = torch.sin(x_transformed)\n",
    "        \n",
    "        return output\n",
    "    def count_params(self):\n",
    "        return self.weight.shape[0] * self.weight.shape[1]\n",
    "\n",
    "    \n",
    "class SinePaintNetwork(nn.Module):\n",
    "    def __init__(self, layer_dims,final_amp = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            layer_dims: List of [input_dim, output_dim] pairs\n",
    "        \"\"\"\n",
    "        super(SinePaintNetwork, self).__init__()\n",
    "        \n",
    "        # Create a list of SinePaint layers according to the dimensions specified\n",
    "        layers = []\n",
    "        for input_dim, output_dim in layer_dims:\n",
    "            layers.append(SinePaint(input_dim, output_dim))\n",
    "        \n",
    "        # Store the layers as a ModuleList\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        if final_amp is None:\n",
    "            self.a = nn.Parameter(torch.randn(1))\n",
    "        else:\n",
    "            self.a = torch.tensor([final_amp])\n",
    "    def forward(self, x):\n",
    "        # Pass the input through each layer in sequence\n",
    "        x = x.unsqueeze(dim=-1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.a * x\n",
    "    def count_params(self):\n",
    "        layer_count = 0\n",
    "        for i in self.layers:\n",
    "            layer_count += i.count_params()\n",
    "        return layer_count + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ae5858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_dim = 3\n",
    "output_dim = 10\n",
    "batch_size = 5\n",
    "\n",
    "model = SinePaint(input_dim, output_dim)\n",
    "print(model.count_params())\n",
    "x = torch.randn(batch_size, input_dim)\n",
    "print(x.shape)\n",
    "output = model(x)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dcbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
